import os
import torch
from flask import Flask, request, jsonify, send_file, send_from_directory
from flask_cors import CORS
from PIL import Image
from datetime import datetime
from diffusers import FluxKontextPipeline

app = Flask(__name__)
CORS(app, origins=[
    "http://localhost:3000",    
    "https://www.wildmindai.com",
    "https://api.wildmindai.com",
    "https://*.vercel.app"
])

# â”€â”€â”€ Load Shared FluxKontext Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ”„ Loading FLUX.1-Kontext pipeline...")
flux_pipe = FluxKontextPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-Kontext-dev",
    torch_dtype=torch.bfloat16
).to("cuda")
print("âœ… FLUX pipeline loaded.")

# â”€â”€â”€ Output Directory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
output_dir = "outputs"
os.makedirs(output_dir, exist_ok=True)

# â”€â”€â”€ Prompt Enhancers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def enhance_logo_prompt(user_prompt: str):
    return f"{user_prompt}, professional logo, minimal design, clean lines"

def optimize_mockup_prompt(user_prompt):
    universal = "Same model uses the product naturally in the scene."
    user_part = user_prompt.strip().capitalize()
    return f"{universal} {user_part}"[:300]

# â”€â”€â”€ Utilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def resize_and_pad(image, size=(512, 512), bg_color=(255, 255, 255)):
    image.thumbnail(size, Image.LANCZOS)
    result = Image.new("RGB", size, bg_color)
    offset = ((size[0] - image.width) // 2, (size[1] - image.height) // 2)
    result.paste(image, offset)
    return result

def create_reference_image(model_img, product_img, width=1024, height=1024):
    model_resized = resize_and_pad(model_img, (int(width * 0.6), height))
    product_resized = resize_and_pad(product_img, (int(width * 0.4), int(width * 0.4)))

    reference = Image.new("RGB", (width, height), (255, 255, 255))
    reference.paste(model_resized, (0, 0))

    product_x = width - product_resized.width - 40
    product_y = (height - product_resized.height) // 2

    if product_resized.mode == "RGBA":
        reference.paste(product_resized, (product_x, product_y), mask=product_resized.split()[3])
    else:
        reference.paste(product_resized, (product_x, product_y))

    return reference

# â”€â”€â”€ Single Smart Generate Endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/generate", methods=["POST"])
def generate():
    try:
        if request.content_type.startswith("application/json"):
            # â”€â”€â”€ Logo Generation â”€â”€â”€
            data = request.get_json()
            prompt = enhance_logo_prompt(data.get("prompt", "").strip())
            num_images = int(data.get("num_images", 1))
            urls = []

            for i in range(num_images):
                generator = torch.manual_seed(42 + i)
                image = flux_pipe(
                    prompt=prompt,
                    guidance_scale=4.5,
                    num_inference_steps=45,
                    generator=generator
                ).images[0]
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"logo_{ts}_{i}.png"
                path = os.path.join(output_dir, filename)
                image.save(path)
                urls.append(f"/download/{filename}")
                print(f"âœ… Logo generated: {filename}")

            return jsonify({ "image_urls": urls })

        elif request.content_type.startswith("multipart/form-data"):
            # â”€â”€â”€ Product With Model Pose â”€â”€â”€
            model_file = request.files["model_image"]
            product_file = request.files["product_image"]
            user_prompt = request.form.get("scene_desc", "studio setting")
            width = int(request.form.get("width", 768))
            height = int(request.form.get("height", 768))

            width = max(512, min(width, 2048)) - (max(512, min(width, 2048)) % 16)
            height = max(512, min(height, 2048)) - (max(512, min(height, 2048)) % 16)

            model_img = Image.open(model_file).convert("RGB")
            product_img = Image.open(product_file).convert("RGB")
            reference = create_reference_image(model_img, product_img, width, height)
            prompt = optimize_mockup_prompt(user_prompt)

            result = flux_pipe(
                image=reference,
                prompt=prompt,
                guidance_scale=4.0,
                num_inference_steps=35,
                generator=torch.manual_seed(42),
                width=width,
                height=height,
                negative_prompt="collage, side by side, split frame, duplicate product, unrealistic"
            ).images[0]

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"mockup_{timestamp}.png"
            output_path = os.path.join(output_dir, filename)
            result.save(output_path)
            print(f"âœ… Mockup generated: {filename}")

            return jsonify({ "image_url": f"/download/{filename}" })

        else:
            return jsonify({ "error": "Unsupported content type" }), 400

    except Exception as e:
        print(f"âŒ Error: {e}")
        return jsonify({ "error": str(e) }), 500

# â”€â”€â”€ Download Route â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/download/<filename>")
def download_file(filename):
    return send_from_directory(output_dir, filename)

@app.route("/health")
def health():
    return jsonify({ "status": "healthy", "model": "FluxKontext", "output_dir": output_dir })

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=7861, debug=True)
